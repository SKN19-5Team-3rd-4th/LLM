from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from typing import TypedDict, Annotated, Optional, Literal, List

from functools import partial
import operator
from dotenv import load_dotenv
import warnings
from pyfiglet import figlet_format
import json
import streamlit as st

from modules.collect import ModelCollect
from modules.recommend import ModelRecommend, tool_rag_recommend
from modules.qna import ModelQna, tool_rag_qna

load_dotenv()

warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=RuntimeWarning)

# ì •ë³´ ì €ì¥ state ì„ ì–¸ --------------------

class GraphState(TypedDict):
    messages: Annotated[list, add_messages]                         # ëª¨ë“  ë©”ì‹œì§€ë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸

    current_stage: Literal["collect", "recommend", "qna", "exit"]   # í˜„ì¬ ì–´ë–¤ ì‘ì—…ì„ í•˜ê³  ìˆëŠ”ì§€ ì €ì¥

    collected_data: Optional[dict]                                  # ì‚¬ìš©ìì—ê²Œì„œ ëª¨ì€ ë°ì´í„°(ì •ë³´)ë¥¼ ì €ì¥í•˜ëŠ” ë”•ì…”ë„ˆë¦¬

    recommend_result: Annotated[Optional[List[str]], operator.add]  # ì‚¬ìš©ìì—ê²Œ ì¶”ì²œí•œ ê²°ê³¼(í•´ë‹¹ ì¶”ì²œ ê²°ê³¼ëŠ” ì¬ì¶”ì²œí• ë•Œì— ê³ ë ¤í•˜ì§€ ì•Šê²Œ í•˜ê¸° ìœ„í•¨)

    # None: ì•„ë¬´ í–‰ë™ë„ í•˜ì§€ ì•ŠìŒ, Skip: ë‹¤ìŒ ë‹¨ê³„ë¡œ, Continue: ì¶”ì²œ ë§Œì¡±, Retry: ì¶”ì²œ ë‹¤ì‹œ ë°›ê¸°, Restart: ì²˜ìŒë¶€í„° ì¬ì‹œì‘, QnA: QnAë¡œ ì´ë™
    user_action: Literal["None", "Skip", "Continue", "Retry", "Restart", "QnA", "Exit"]


initial_state = {
    "messages": [AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”. AIì…ë‹ˆë‹¤.")],
    "current_stage": "collect",
    "user_action": "None",
    "collected_data": {
                "purpose": None,            
                "preferred_style": None,    
                "preferred_color": None,
                "plant_type": None,
                "season": None,
                "humidity": None,
                "has_dog": None,
                "has_cat": None,
                "isAirCond": None,
                "watering_frequency": None,
                "user_experience": None,
                "emotion": None
            },
    "recommend_result": " "
}
### tools ì„ ì–¸ ---------------------------
# tool í•¨ìˆ˜ ì„ ì–¸

# tools ì—ëŠ”, ê°ê° ì´ë¯¸ì§€ ì²˜ë¦¬ í˜¹ì€ RAGë¥¼ ìˆ˜í–‰í•˜ëŠ” ì„¸ê°€ì§€ í•¨ìˆ˜ê°€ ë“¤ì–´ê°€ì•¼ í•¨
tools = [tool_rag_recommend, tool_rag_qna]

### ë…¸ë“œ ì„ ì–¸ -----------------------------

def node_collect(state: GraphState, collector: ModelCollect):
    response, message, collected_data = collector.get_response(state["messages"], state["collected_data"])  # ì–´ë–¤ ì •ë³´ë¥¼ ì „ë‹¬í–ˆëŠ”ì§€ ì•Œì•„ì•¼ í•˜ë‹ˆê¹Œ collected_dataë„ ê°™ì´ ì „ë‹¬
    
    return {
        "current_stage" : "collect",
        "messages": [response],
        "collected_data": collected_data,
    }

def node_recommend(state: GraphState, recommender: ModelRecommend):

    response, recommend_result = recommender.get_response(state["messages"], state["collected_data"], state["recommend_result"])  
    # collected_data (ì •ë³´ë¥¼ ì €ì¥í•œ ë”•ì…”ë„ˆë¦¬) ë„ ê°™ì´ ì „ë‹¬í•´ì£¼ëŠ” ê²ƒì´ ë‚«ì§€ ì•Šì„ì§€...
    # ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤˜ì•¼í•  ê°’ : responseì™€, ì¶”ì²œ ê²°ê³¼: recommend_resultë¥¼ ê°™ì´ ë°˜í™˜í•´ì¤˜ì•¼ í• ë“¯ (ì¶”ì²œ ê²°ê³¼ëŠ” ë‹¤ì‹œ ì¶”ì²œ ë°›ì„ë•Œ ì œì™¸í•˜ê¸° ìœ„í•¨)
    # collected_data: dict         # ì‚¬ìš©ìì—ê²Œì„œ ëª¨ì€ ë°ì´í„°(ì •ë³´)ë¥¼ ì €ì¥í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
    # recommend_result: List[str]  # ì‚¬ìš©ìì—ê²Œ ì¶”ì²œí•œ ê²°ê³¼(í•´ë‹¹ ì¶”ì²œ ê²°ê³¼ëŠ” ì¬ì¶”ì²œí• ë•Œì— ê³ ë ¤í•˜ì§€ ì•Šê²Œ í•˜ê¸° ìœ„í•¨)

    print(type(response))

    return {
        "current_stage" : "recommend",
        "messages": [response],
        "recommend_result": recommend_result,
    }

def node_qna(state: GraphState, chatbot: ModelQna):
    response = chatbot.get_response(state["messages"])

    return {
        "current_stage": "qna",
        "messages": [response],
    }

def node_end_state(state:GraphState):
    return {
        "current_stage": "exit"
    }


### router ì„ ì–¸ -----------------------

# í•´ë‹¹ routerì˜ ê²°ê³¼ì— ë”°ë¼, ì–´ë–¤ ë…¸ë“œë¡œ í–¥í• ì§€ ì»¨íŠ¸ë¡¤
def main_router(state: GraphState):
    stage = state["current_stage"]
    action = state["user_action"]

    if action == "Restart":
        return "restart"
    
    if action == "Exit":
        return "exit"
    
    if action == "QnA":
        return "qna"
    
    
    if stage == "collect":
        if action == "Continue":
            return "recommend"
        
        if ModelCollect.is_data_enough(state["collected_data"]):
            return "recommend"
        else:
            return "collect"
    
    elif stage == "recommend":
        if action == "Continue":
            return "exit"
        
        elif action == "QnA":
            return "qna"
        else:   # action == "Retry"
            return "recommend"
    
    elif stage == "qna":
        return "qna"
    
    elif stage == "exit":
        return "exit"
    
def is_tool_calls(state: GraphState):
    last_message = state["messages"][-1]

    if last_message.tool_calls:
        return "tool_call"
    else:
        return "done"
    
def tool_back_to_caller(state: GraphState) -> str:
    current_state = state.get("current_stage")

    if current_state == "recommend":
        print(f"[ToolMessages] [RAG] [Pinecone Index name is plant-rec]")
    elif current_state == "qna":
        print(f"[ToolMessages] [RAG] [Pinecone Index name is plant-qna]")
    print(state["messages"][-1])

    if current_state and current_state in ["collect", "recommend", "qna"]:
        return current_state
    
    return "exit"


model_collect = ModelCollect(tools)
model_recommend = ModelRecommend(tools)
model_qna = ModelQna(tools)

workflow = StateGraph(GraphState)

workflow.add_node("collect", partial(node_collect, collector=model_collect))
workflow.add_node("recommend", partial(node_recommend, recommender=model_recommend))
workflow.add_node("qna", partial(node_qna, chatbot=model_qna))
workflow.add_node("exit", node_end_state)
workflow.add_node("rag_tool", ToolNode(tools))

workflow.add_edge("exit", END)
workflow.add_edge("collect", END)

workflow.add_conditional_edges(
    START,
    main_router,
    {
        "collect": "collect",
        "recommend": "recommend",
        "qna": "qna",
        "exit": "exit"
    }
)

workflow.add_conditional_edges(
    "recommend",
    is_tool_calls,
    {
        "tool_call": "rag_tool",
        "done": END,
    }
)

workflow.add_conditional_edges(
    "qna",
    is_tool_calls,
    {
        "tool_call": "rag_tool",
        "done": END,
    }
)

workflow.add_conditional_edges(
    "rag_tool",
    tool_back_to_caller,
    {
        "collect": "collect",
        "recommend": "recommend",
        "qna": "qna",
        "exit": "exit",
    }
)

# "compile()" ì€ rerunë§ˆë‹¤ ì¬ì‚¬ìš©ë˜ë„ë¡ session_stateì— ì €ì¥
if "app" not in st.session_state:
    memory = MemorySaver()
    st.session_state.app = workflow.compile(checkpointer=memory)


# ==========================================
# [4] Streamlit UI ì‹œì‘
# ==========================================

st.set_page_config(page_title="PLANT AI", page_icon="ğŸŒ¿")

st.title("ğŸŒ¿ PLANT AI")
st.caption("ë‚˜ë§Œì˜ ì‹ë¬¼ ì¶”ì²œ íŒŒíŠ¸ë„ˆ (LangGraph Powered)")



app = st.session_state.app

if "thread_id" not in st.session_state:
    st.session_state.thread_id = "user_1234" # ê³ ìœ  ID

config = {"configurable": {"thread_id": st.session_state.thread_id}}

# ì´ˆê¸° ë©”ì‹œì§€/ìƒíƒœê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
current_state_snapshot = app.get_state(config)
if not current_state_snapshot.values:
    # ì´ˆê¸° ìƒíƒœ ì£¼ì…
    initial_state = {
        "messages": [AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”. AIì…ë‹ˆë‹¤.")],
        "current_stage": "collect",
        "user_action": "None",
        "collected_data": {
            "purpose": None, "preferred_style": None, "preferred_color": None,
            "plant_type": None, "season": None, "humidity": None,
            "has_dog": None, "has_cat": None, "isAirCond": None,
            "watering_frequency": None, "user_experience": None, "emotion": None
        },
        "recommend_result": []
    }
    # ì´ˆê¸° ì‹¤í–‰ìœ¼ë¡œ ìƒíƒœ ì„¤ì •
    app.invoke(initial_state, config=config)
    st.rerun()

# í˜„ì¬ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
state_values = app.get_state(config).values
messages = state_values.get("messages", [])
current_stage = state_values.get("current_stage", "collect")
collected_data = state_values.get("collected_data", {})

# ==========================================
# [ì‚¬ì´ë“œë°”]
# ==========================================
with st.sidebar:
    st.header("ğŸ“Š ì§„í–‰ ìƒí™©")
    stage_map = {"collect": "ì •ë³´ ìˆ˜ì§‘", "recommend": "ì¶”ì²œ", "qna": "ìƒë‹´", "exit": "ì¢…ë£Œ"}
    st.info(f"í˜„ì¬ ë‹¨ê³„: **{stage_map.get(current_stage, current_stage)}**")

    if current_stage == 'collect' and collected_data:
        total = len(collected_data)
        filled = sum(1 for v in collected_data.values() if v is not None)
        if total > 0:
            pct = int((filled / total) * 100)
            st.progress(pct / 100)
            st.write(f"ì •ë³´ ìˆ˜ì§‘ë¥ : {pct}%")

    if st.button("ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘"):
        # ìƒíƒœ ë¦¬ì…‹ ë¡œì§ (ìƒˆ thread_id ë°œê¸‰ ë“±)
        st.session_state.thread_id = f"user_{int(st.session_state.thread_id.split('_')[1]) + 1}"
        st.rerun()

# ==========================================
# [ë©”ì¸] ì±„íŒ…ì°½
# ==========================================

# ë©”ì‹œì§€ íŒŒì‹± í•¨ìˆ˜
def parse_ai_content(content):
    if isinstance(content, str) and content.startswith('{'):
        try:
            data = json.loads(content)
            if "assistant_message" in data: return data["assistant_message"]
            if "response" in data: return data["response"]
        except: pass
    return content

# íˆìŠ¤í† ë¦¬ ì¶œë ¥
for msg in messages:
    if isinstance(msg, HumanMessage):
        with st.chat_message("user"):
            st.write(msg.content)
    elif isinstance(msg, AIMessage):
        if msg.content:
            text = parse_ai_content(msg.content)
            with st.chat_message("assistant", avatar="ğŸŒ¿"):
                st.write(text)

# ==========================================
# [ì…ë ¥] ì²˜ë¦¬
# ==========================================
if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ì…ë ¥ ì¦‰ì‹œ í‘œì‹œ
    with st.chat_message("user"):
        st.write(user_input)
    
    # Action ê²°ì • ë¡œì§
    action = "None"
    actual_input = user_input

    if user_input.lower() == "ì¢…ë£Œ":
        action = "Exit"
    elif user_input.lower() == "qna":
        action = "QnA"
        actual_input = "ì•ˆë…•? ìê¸°ì†Œê°œ í•´ì¤˜" # ìƒíƒœ ì „í™˜ íŠ¸ë¦¬ê±°ìš©
    elif user_input.lower() == "next" or user_input == "ì¶”ì²œí•´ì¤˜":
        action = "Continue" # í˜¹ì€ ë¡œì§ì— ë”°ë¼ Skip
        actual_input = "ì¶”ì²œí•´ì¤˜"

    # LangGraph ì…ë ¥ í˜ì´ë¡œë“œ
    input_payload = {
        "messages": [HumanMessage(content=actual_input)],
        "user_action": action
    }

    with st.chat_message("assistant", avatar="ğŸŒ¿"):
        with st.spinner("ìƒê° ì¤‘..."):
            # Graph ì‹¤í–‰
            result = app.invoke(input_payload, config=config)
            
            # ë§ˆì§€ë§‰ ì‘ë‹µ ì¶œë ¥
            last_msg = result["messages"][-1]
            if isinstance(last_msg, AIMessage):
                st.write(parse_ai_content(last_msg.content))
            
            # ìƒíƒœ ê°±ì‹ ì„ ìœ„í•´ ë¦¬ëŸ° (í•„ìˆ˜ëŠ” ì•„ë‹ˆì§€ë§Œ UI ë™ê¸°í™” í™•ì‹¤í•¨)
            # st.rerun()