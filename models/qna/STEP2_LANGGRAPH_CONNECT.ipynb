{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b998ad",
   "metadata": {},
   "source": [
    "### 목표: RAG Q&A 동작 구축 → 그 다음에 LangGraph 연결 → 마지막에 Memory/ToolNode 확장\n",
    "\n",
    "#### 2단계: LangGraph 연결\n",
    "- 1단계에서 만든 RAG QnA를 Class로 정리\n",
    "- LangGraph Node로 연결 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec47a0d1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b7fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain.tools import tool\n",
    "from functools import partial\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from typing import TypedDict, Annotated, Optional, Literal, List\n",
    "from dotenv import load_dotenv \n",
    "import operator\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"plant-qna\"\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "\n",
    "@tool\n",
    "def tool_rag_qna(query: str) -> str:\n",
    "    \"\"\"식물 상담 QnA 전용 RAG 도구\"\"\"\n",
    "    vector_store = PineconeVectorStore(\n",
    "        index=index, \n",
    "        embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    )\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})   \n",
    "    retrievals = retriever.batch([query]) \n",
    "    \n",
    "    return str(retrievals[0])\n",
    "\n",
    "\n",
    "class ModelQna:\n",
    "    def __init__(self, tools):        \n",
    "        self.tools = tools      \n",
    "\n",
    "    def get_response(self, messages):\n",
    "        \n",
    "        prompt = \"\"\"\n",
    "        너는 식물에 대해 차분하게 상담해 주는 전문가이다.\n",
    "        아래 형식을 반드시 지키되, 실제 상담사가 말하듯 자연스럽고 단정적인 말투로 작성한다.\n",
    "\n",
    "        ### 답변 방식 ###\n",
    "        - 첫 문장은 사용자의 고민에 대한 핵심 답변을 한 줄로 요약한다. (채팅 응답처럼)\n",
    "        - 이후 이어지는 RAG 정보는 비슷한 사례의 해결 방향을 '요약 3줄'로 정리한다.\n",
    "        - 모든 문장은 따뜻하지만 과하지 않게, 실제 상담사가 말하듯 단정적으로 말한다.\n",
    "        - 마지막 문장은 대화를 이어가기 위해 질문형으로 마무리한다.\n",
    "        \n",
    "        ### 출력 형식 ###\n",
    "        [사용자의 상황을 판단해서 가장 핵심적인 조언을 한 문장으로 제시]\n",
    "        [현재 상황에 맞는 다음 추가 질문 유도]\n",
    "        \"\"\"\n",
    "        \n",
    "        system_msg = SystemMessage(prompt)\n",
    "        input_msg = [system_msg] + messages\n",
    "\n",
    "        model = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\", \n",
    "            temperature=0.3\n",
    "        ).bind_tools(self.tools)\n",
    "\n",
    "        response = model.invoke(input_msg)\n",
    "        \n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a77b6fe",
   "metadata": {},
   "source": [
    "- 랭그래프 연결은 준영님"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
