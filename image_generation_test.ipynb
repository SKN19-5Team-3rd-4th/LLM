{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f42540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/project3/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/project3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/anaconda3/envs/project3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/ipykernel/utils.py\", line 71, in preserve_context\n",
      "    return await f(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/6l/zt09qyzx26dfq19r9_r0gwk40000gn/T/ipykernel_42955/4076692961.py\", line 1, in <module>\n",
      "    from langchain_openai import ChatOpenAI\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/langchain_openai/__init__.py\", line 3, in <module>\n",
      "    from langchain_openai.chat_models import AzureChatOpenAI, ChatOpenAI\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/langchain_openai/chat_models/__init__.py\", line 3, in <module>\n",
      "    from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/langchain_openai/chat_models/azure.py\", line 11, in <module>\n",
      "    from langchain_core.language_models import LanguageModelInput\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/langchain_core/language_models/__init__.py\", line 108, in __getattr__\n",
      "    result = import_attr(attr_name, module_name, __spec__.parent)\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/langchain_core/_import_utils.py\", line 35, in import_attr\n",
      "    module = import_module(f\".{module_name}\", package=package)\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/langchain_core/language_models/base.py\", line 41, in <module>\n",
      "    from transformers import GPT2TokenizerFast  # type: ignore[import-not-found]\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/transformers/__init__.py\", line 27, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/transformers/utils/__init__.py\", line 24, in <module>\n",
      "    from .auto_docstring import (\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/transformers/utils/auto_docstring.py\", line 30, in <module>\n",
      "    from .generic import ModelOutput\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/transformers/utils/generic.py\", line 51, in <module>\n",
      "    import torch\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/opt/anaconda3/envs/project3/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/anaconda3/envs/project3/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "import json\n",
    "from typing import TypedDict, Annotated, Optional, Literal, List\n",
    "\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f9e407f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Response' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 48\u001b[0m\n\u001b[1;32m     20\u001b[0m flower_img \u001b[38;5;241m=\u001b[39m image_to_base64(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatas/images/images.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mresponses\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     23\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-5.1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_fidelity\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m\"\u001b[39m}],\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 48\u001b[0m image_base64 \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mb64_json\n\u001b[1;32m     49\u001b[0m img_bytes \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64decode(image_base64)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medited_output.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/project3/lib/python3.10/site-packages/pydantic/main.py:1026\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Response' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def image_to_base64(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "# room_file = client.files.create(\n",
    "#     file=open(\"datas/images/test1.jpg\", \"rb\"),\n",
    "#     purpose=\"vision\"\n",
    "# )\n",
    "\n",
    "# # 칼랑코에 이미지 업로드\n",
    "# kalanchoe_file = client.files.create(\n",
    "#     file=open(\"datas/images/images.jpeg\", \"rb\"),\n",
    "#     purpose=\"vision\"\n",
    "# )\n",
    "\n",
    "room_img = image_to_base64(\"datas/images/test1.jpg\")\n",
    "flower_img = image_to_base64(\"datas/images/images.jpeg\")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": \"\"\"\n",
    "                두 장의 이미지를 자연스럽게 합성해줘.\n",
    "                reference_image_1은 거실 사진이고,\n",
    "                reference_image_2는 꽃 사진이야.\n",
    "                reference_image_2에 있는 꽃을 reference_image_1의 테이블 위에 자연스럽게 배치해줘.\n",
    "                \"\"\"},\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/png;base64,{room_img}\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/png;base64,{flower_img}\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    tools=[{\"type\": \"image_generation\", \"input_fidelity\": \"high\"}],\n",
    ")\n",
    "\n",
    "image_base64 = response.data[0].b64_json\n",
    "img_bytes = base64.b64decode(image_base64)\n",
    "\n",
    "with open(\"edited_output.png\", \"wb\") as f:\n",
    "    f.write(img_bytes)\n",
    "\n",
    "print(\"saved edited_output.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78f06d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = [\n",
    "    output.result\n",
    "    for output in response.output\n",
    "    if output.type == \"image_generation_call\"\n",
    "]\n",
    "\n",
    "if image_data:\n",
    "    image_base64 = image_data[0]\n",
    "    with open(\"flower_image_create.png\", \"wb\") as f:\n",
    "        f.write(base64.b64decode(image_base64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed5b35fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "result = client.images.edit(\n",
    "    model=\"gpt-image-1\",\n",
    "    image=[open(\"datas/images/test1.jpg\", \"rb\"), open(\"datas/images/images.jpeg\", \"rb\")],\n",
    "    prompt= \"\"\"\n",
    "                두 장의 이미지를 자연스럽게 합성해줘.\n",
    "                reference_image_1은 거실 사진이고,\n",
    "                reference_image_2는 꽃 사진이야.\n",
    "                reference_image_2에 있는 꽃을 reference_image_1의 테이블 위에 자연스럽게 배치해줘.\n",
    "                \"\"\",\n",
    "    input_fidelity=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result.data[0].b64_json\n",
    "image_bytes = base64.b64decode(image_base64)\n",
    "\n",
    "# Save the image to a file\n",
    "with open(\"flower_image_edit.png\", \"wb\") as f:\n",
    "    f.write(image_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dd9a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(url, to_base64=False):\n",
    "    if to_base64 is True:\n",
    "        image_bytes = open(url, \"rb\").read()\n",
    "        image_b64 = base64.b64encode(image_bytes).decode('utf-8')\n",
    "        return image_b64\n",
    "    else:\n",
    "        image = Image.open(url)\n",
    "        return image\n",
    "    \n",
    "def image_to_base64(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e17670a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(b64):\n",
    "    image_data = base64.b64decode(b64)\n",
    "    img = Image.open(io.BytesIO(image_data))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0931aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analysis(original_image, reference_text):\n",
    "    system_prompt = f\"\"\"\n",
    "\n",
    "    다음 예시 설명은 사용자가 입력하는 사진과 유사한 분위기의 사진을 설명한 예시다.\n",
    "    예시 설명을 참고하여 사진에 대한 설명을 다음 형식으로 출력하여라.\n",
    "    ### 출력 형식 : \n",
    "\n",
    "\n",
    "    ### 예시 설명 : {reference_text}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    human_prompt = [\n",
    "        {\"type\": \"text\", \"text\": \" \"},\n",
    "        {\"type\": \"image\", \"base64\": original_image},\n",
    "        {\n",
    "            \"type\": \"input_image\",\n",
    "            \"image_base64\": original_image\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model = ChatOpenAI(model=\"gpt-5.1\")\n",
    "\n",
    "    messages = []\n",
    "    system_message = SystemMessage(system_prompt)\n",
    "    messages.append(system_message)\n",
    "\n",
    "    human_message = HumanMessage(content=human_prompt)\n",
    "    messages.append(human_message)\n",
    "\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d040cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def get_analysis(original_image, reference_text):\n",
    "    client = OpenAI()\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "\n",
    "    다음 예시 설명은 사용자가 입력하는 사진과 유사한 분위기의 사진을 설명한 예시다.\n",
    "    예시 설명을 참고하여 사진에 대한 설명을 다음 형식으로 출력하여라.\n",
    "    ### 출력 형식 : \n",
    "\n",
    "\n",
    "    ### 예시 설명 : {reference_text}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    human_prompt = [\n",
    "        {\"type\": \"text\", \"text\": \" \"},\n",
    "        {'type': 'image_url', \n",
    "         'image_url': {'url': f'data:image/jpeg;base64, {original_image}'}\n",
    "         }   \n",
    "    ]\n",
    "\n",
    "    messages = [\n",
    "        {'role': 'system',\n",
    "         'content': system_prompt},\n",
    "         {'role': 'user',\n",
    "          'content': human_prompt}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-5.1',\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bfcb900",
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  \"\"\"\n",
    "이 욕실 인테리어는 밝고 세련된 느낌을 주고 있습니다. 화장대는 부드러운 파란색으로 칠해져 있으며, 깔끔한 흰색 대리석 또는 석재 상판이 매치되어 있습니다. 세면대 위쪽에는 긴 직사각형 모양의 거울이 설치되어 있고, 거울 양옆으로 LED 조명이 부착되어 있어 현대적인 분위기를 강조합니다. \n",
    "\n",
    "수도꼭지는 금속성 마감으로, 세면대의 깔끔한 디자인과 잘 어울립니다. 화장대 위에는 여러 개의 흰색 꽃병이 장식되어 있으며, 그 안에는 생화나 인조 꽃들이 꽂혀 있어 공간에 생기를 더합니다. 주변 벽은 중립적인 색조로 되어 있어 전체적인 색상 조화가 잘 이루어지고 있습니다. \n",
    "\n",
    "천장에는 회색의 천장 선풍기가 설치되어 있어 기능성과 함께 스타일리시한 요소를 더하고 있습니다. 전체적으로 밝고 깔끔한 느낌을 주면서도 세부적인 부분에서 세련된 디자인을 보여주는 욕실입니다.\n",
    "\"\"\"\n",
    "\n",
    "url = 'datas/images/test1.jpg'\n",
    "\n",
    "image = image_to_base64(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecf1463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_analysis(image, reference_text=text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22e03d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-Cislerstbojr1jwfAhcNNKHSy1bto', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='이 세탁실 인테리어는 파스텔 톤의 상쾌하고 깔끔한 분위기를 주고 있습니다. 상·하부 수납장은 부드러운 민트색으로 마감되어 있으며, 문에 세로 라인이 들어간 클래식한 스타일의 패널이 적용되어 단정한 느낌을 줍니다. 상판은 밝은 화이트 또는 연한 대리석 느낌의 소재로 되어 있어 전체적으로 깨끗하고 밝은 인상을 강조합니다. \\n\\n좌측에는 오픈 선반 구조의 수납장이 있어, 라탄 바구니가 수납되어 실용성과 디자인을 동시에 살리고 있습니다. 그 옆에는 작은 싱크대와 은색 수전이 설치되어 있어, 세탁 전 손빨래나 간단한 세척을 할 수 있는 작업 공간으로 활용됩니다. 벽면은 하얀 타일로 마감되어 은은한 광택이 느껴지며, 민트색 수납장과 조화롭게 어우러져 산뜻한 느낌을 더합니다. \\n\\n우측에는 세탁기와 건조기가 나란히 빌트인 형태로 배치되어 있고, 그 위쪽으로는 상부장이 설치되어 있어 수납 공간을 극대화하고 있습니다. 상부장 아래에는 짧은 행거 봉이 설치되어 셔츠나 상의를 걸어둘 수 있으며, 잘 다려진 흰 셔츠들이 걸려 있어 정돈된 인상을 줍니다. 상판 위에는 시계, 바구니, 화분, 난꽃 등 소품들이 올려져 있어 공간에 포인트를 주면서도 아늑하고 생활감 있는 분위기를 만들어줍니다. \\n\\n짙은 톤의 나무 마루 바닥이 밝은 컬러의 상부장과 대비를 이루어 고급스럽고 안정감 있는 느낌을 주며, 전체적으로 기능성과 미적인 요소가 잘 조화된 세련된 세탁실 공간입니다.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1764812994, model='gpt-5.1-2025-11-13', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=439, prompt_tokens=531, total_tokens=970, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ac520fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(original_image, flower_image, flower_name, references):\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    room_b64 = image_to_base64(original_image)\n",
    "    flower_b64 = image_to_base64(flower_image)\n",
    "\n",
    "    system_message = [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\":\n",
    "                f\"다음 두 이미지를 참고해서 방 이미지에 꽃을 합성해줘. 해당 꽃의 이름은 {flower_name} 이야. 아래 references에 어디에 배치할지 참고할 정보가 포함되어 있어.\"\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    human_message = [\n",
    "\n",
    "            # 방 이미지\n",
    "            {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64, {room_b64}'}},\n",
    "            {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64, {flower_b64}'}},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"REFERENCES: {references}\"\n",
    "            },\n",
    "            # 생성 이미지 요청\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"위 두 이미지를 바탕으로 references 정보를 반영하여 정확하게 합성된 최종 인테리어 이미지를 생성해줘.\",\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    messages = [\n",
    "        {'role': 'system',\n",
    "         'content': system_message},\n",
    "        {'role': 'user',\n",
    "         'content': human_message}\n",
    "    ]\n",
    "\n",
    "    image = client.images.generate(\n",
    "        model='dall-e-3',\n",
    "        messages=messages\n",
    "    )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf45b8bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Missing required arguments; Expected either ('prompt') or ('prompt' and 'stream') arguments to be given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m image_response \u001b[38;5;241m=\u001b[39m \u001b[43mget_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatas/images/test1.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatas/images/images.jpeg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m산세베리아\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[72], line 40\u001b[0m, in \u001b[0;36mget_image\u001b[0;34m(original_image, flower_image, flower_name, references)\u001b[0m\n\u001b[1;32m     17\u001b[0m human_message \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m         \u001b[38;5;66;03m# 방 이미지\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m         }\n\u001b[1;32m     31\u001b[0m     ]\n\u001b[1;32m     33\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     34\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     35\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: system_message},\n\u001b[1;32m     36\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     37\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: human_message}\n\u001b[1;32m     38\u001b[0m ]\n\u001b[0;32m---> 40\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdall-e-3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[0;32m/opt/anaconda3/envs/project3/lib/python3.10/site-packages/openai/_utils/_utils.py:285\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: Missing required arguments; Expected either ('prompt') or ('prompt' and 'stream') arguments to be given"
     ]
    }
   ],
   "source": [
    "image_response = get_image('datas/images/test1.jpg', 'datas/images/images.jpeg', '산세베리아', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08466181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'지금 바로 이미지를 직접 합성해서 출력할 수는 없지만, 제공해주신 두 이미지를 바탕으로 세탁실(방) 사진에 산세베리아를 자연스럽게 합성하는 방법을 단계별로 설명해드릴게요. 포토샵이나 비슷한 편집 프로그램에서 그대로 따라 하시면 됩니다.\\n\\n---\\n\\n## 1. 배치 위치 설정 (references 반영)\\n\\nreferences 내용을 세탁실 이미지에 맞게 해석하면:\\n\\n- 밝고 세련된 느낌 유지  \\n- 상판 위에 여러 꽃병/식물이 올려져 있는 구도  \\n- 공간에 생기를 더하는 역할의 식물\\n\\n따라서 산세베리아는 **세탁실 상판 위, 수전(수도꼭지) 주변**에 배치하는 것이 가장 자연스럽습니다.\\n\\n**추천 위치 2곳:**\\n\\n1. **왼쪽 상판, 현재 보라색 난초 화분 있는 자리**  \\n   - 난초 화분을 산세베리아 화분으로 대체  \\n   - references의 “여러 개의 흰색 꽃병” 느낌을 살리려면, 산세베리아 뒤나 옆에 작은 흰색 액세서리나 작은 병들을 그대로 두거나 살짝 보이게 배치\\n\\n2. **세탁기와 싱크대 사이 상판 중앙–우측**  \\n   - 원래 유칼립투스가 꽂힌 화병이 있는 위치에 산세베리아를 두고, 화병은 옆으로 살짝 이동  \\n   - 세면대(싱크대) 위쪽에 식물들이 놓인 욕실 레퍼런스 구도를 재현하게 됨\\n\\n이 중 **1번(왼쪽 상판)** 이 가장 조화롭고 시선이 잘 모이는 위치입니다.\\n\\n---\\n\\n## 2. 산세베리아 잘라내기\\n\\n1. 산세베리아 이미지(두 번째 이미지)를 열기  \\n2. **선택 도구** (펜툴, 퀵 셀렉션, 객체 선택 등)를 사용해  \\n   - 잎 전체 + 화분만 정교하게 선택  \\n   - 흰 배경은 선택에서 제외\\n3. 선택 영역을 **마스크**로 만들거나,  \\n   - `Ctrl/Cmd + J` 로 새 레이어에 복사해 산세베리아만 분리\\n\\n---\\n\\n## 3. 세탁실 이미지에 붙여넣기\\n\\n1. 분리한 산세베리아 레이어를 **세탁실 이미지** 문서로 드래그  \\n2. `Ctrl/Cmd + T` (자유 변형)으로 크기, 위치 조정  \\n   - 상판 깊이와 다른 오브제(난초, 화병) 크기를 기준으로 스케일을 맞춤  \\n   - 산세베리아 잎 끝이 상부 수납장 하단보다 약간 아래나 비슷한 높이가 되도록 키우면 비율이 안정적\\n\\n---\\n\\n## 4. 원근 및 배치 정교화\\n\\n1. **바닥과 상판의 각도**를 보고, 필요시 살짝 `왜곡(Warp)` 또는 `Perspective`로  \\n   - 화분 윗면의 타원이 상판과 비슷한 각도로 보이도록 맞추기\\n2. 화분 밑부분이 상판에 딱 **닿게** 배치  \\n   - 화분 아래에 살짝 그림자가 생기도록 하려면, 상판과 완전히 밀착해 놓기\\n\\n---\\n\\n## 5. 조명·색감 맞추기\\n\\n세탁실 사진은:\\n\\n- 부드러운 자연광 + 실내광  \\n- 전체적으로 **차가운 파스텔 톤**\\n\\n이에 맞추려면 산세베리아 레이어에서:\\n\\n1. **색조/채도(Hue/Saturation)**  \\n   - 채도(Saturation)를 약간 줄이기(-5 ~ -15)  \\n   - 너무 진한 녹색이면 옆 인테리어와 어울리지 않음\\n2. **색상 균형(Color Balance)** 또는 **커브/레벨( Curves / Levels )**  \\n   - 밝은 톤 쪽에서 약간 **시안/블루**를 더해 전체 톤을 차갑게  \\n   - 이미지 전체 밝기와 비슷하게 Midtones를 약간 올리기\\n3. 필요하다면 **카메라 로우 필터**(Camera Raw Filter)에서  \\n   - Clarity와 Texture를 약간 낮춰(–5 ~ –10)  \\n   - 원본 세탁실 사진의 부드러운 느낌과 질감을 맞춤\\n\\n---\\n\\n## 6. 그림자 추가\\n\\n자연스럽게 보이려면 그림자가 핵심입니다.\\n\\n1. 산세베리아 레이어를 선택 후, 레이어를 복제  \\n2. 복제 레이어를 **검정(#000)** 으로 채우고,  \\n   - `Filter > Blur > Gaussian Blur` 로 적당히 흐리게 (5~15px 정도, 해상도에 따라 조절)  \\n3. 그림자 레이어를 화분 밑으로 이동시키고  \\n   - 상판 뒤쪽 벽 쪽으로 약간 길게 늘리거나 (빛이 천장/창문에서 오는 방향 고려)  \\n4. **레이어 모드**를 `Multiply`, 불투명도 30~50% 정도로 조절\\n\\n벽 쪽에 밀착되어 있는 배치라면, 벽에도 살짝 세로 그림자를 만들어주면 훨씬 자연스럽습니다.\\n\\n---\\n\\n## 7. 주변 오브제와의 관계 조정\\n\\n- 기존 난초 화분이 있는 자리에 산세베리아를 올린다면  \\n  1. 난초 레이어(혹은 이미지 영역)를 선택해 삭제하거나 마스크로 가리기  \\n  2. 산세베리아 뒤로 기존의 **작은 소품(트레이, 병 등)** 일부가 약간 보이게 레이어 순서를 조정  \\n     - 이렇게 하면 references에서 말한 “여러 개의 흰색 꽃병” 느낌과 비슷한 ‘플로럴/데코 존’을 구현할 수 있음\\n\\n---\\n\\n## 8. 최종 점검\\n\\n1. 줌 아웃해서 세탁기, 수납장, 의류와 함께 봤을 때  \\n   - 산세베리아가 과하게 크거나 작아 보이지 않는지  \\n2. 전체 색감이 하나의 사진처럼 통일되는지  \\n   - 필요하다면 최상단에 **전체 컬러 룩업/조정 레이어**(예: Color Lookup, Curves)를 살짝 적용해 전체 톤을 묶어줍니다.\\n\\n---\\n\\n요약하면:  \\n- 산세베리아는 **세탁실 왼쪽 상판(난초 자리)** 에 배치  \\n- 크기는 상부장 하단 조금 아래까지 오는 정도  \\n- 채도·색온도를 낮게 맞추고, 상판 위에 맞는 방향의 부드러운 그림자 추가  \\n\\n편집 도중 중간 결과를 보여주시면, 구체적으로 “여기서 더 키워라/어둡게 해라/그림자 각도 바꿔라” 식으로 디테일 피드백도 도와줄 수 있습니다.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_response.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
